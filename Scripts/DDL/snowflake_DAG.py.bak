import logging

import airflow
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.contrib.hooks.snowflake_hook import SnowflakeHook
from datetime import datetime, timedelta
from airflow.contrib.operators.snowflake_operator import SnowflakeOperator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

default_args = {"owner": "Airflow",
'depends_on_past': False,
'email': ['deepbhattacharyya@deloitte.com'],
'email_on_failure': False,
'email_on_retry': False,
'retries': 1,
'start_date': datetime(2022,2,18)}

dag = DAG(
    dag_id="snowflake_connector", default_args=default_args, schedule_interval=None
)

create_insert_query = [
    """create or replace table BMT_DEMO.AIRFLOW_CONN_DEMO (amount number);""",
    """insert into BMT_DEMO.AIRFLOW_CONN_DEMO values(1),(2),(3);""",
]


def row_count(**context):
    dwh_hook = SnowflakeHook(snowflake_conn_id="conn_snowflake")
    result = dwh_hook.get_first("select count(*) from BMT_DEMO.AIRFLOW_CONN_DEMO")
    logging.info("Number of rows in `test_table`  - %s", result[0])


with dag:
    create_insert = SnowflakeOperator(
        task_id="snowfalke_create",
        sql=create_insert_query,
        snowflake_conn_id="conn_snowflake",
        dag=dag
    )

    get_count = PythonOperator(task_id="get_count", python_callable=row_count,dag=dag)
create_insert >> get_count

